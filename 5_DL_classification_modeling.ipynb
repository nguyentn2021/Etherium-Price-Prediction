{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896ac136-1273-4b7f-9f48-91aaaedb70cb",
   "metadata": {},
   "source": [
    "## Ethereum Price Classification Model using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc35df7c-92c8-42fa-a8c4-f7679852caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping \n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score, classification_report\n",
    "\n",
    "from keras.backend import clear_session\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98afaf-295e-43d9-83b1-bd0c8e4d7be4",
   "metadata": {},
   "source": [
    "##### First of all, I define some functions we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814bc599-458c-46ff-b323-9eeb2d784ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_dataset(window_length, data, index_target):\n",
    "    \n",
    "    \"\"\"\n",
    "    The LSTM needs data with the format of [samples, time steps, features], so we create N samples, window_length time steps per sample, and number of features\n",
    "    \"\"\"\n",
    "    x, y = [], []\n",
    "    data_len = data.shape[0]\n",
    "    for i in range(window_length, data_len):\n",
    "        x.append(data[i-window_length:i,:])\n",
    "        y.append(data[i, index_target])\n",
    "    \n",
    "    # Convert the x and y to numpy arrays\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a7f1fb-40e7-4d8a-b7af-9f6665d25405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classifier_metrics(y_test, y_pred):\n",
    "    \n",
    "    \"\"\" Return metrics for binary classification models \"\"\"\n",
    "    \n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    print('Precision score: ', precision_score(y_test, y_pred))\n",
    "    print('F1 score: ', f1_score(y_test, y_pred))\n",
    "    print('Recall score: ', recall_score(y_test, y_pred))\n",
    "    print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf6a49d2-7b12-4c27-b62b-6a6e98780e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "    \"\"\" Plot training and validation loss \"\"\"\n",
    "    \n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(accuracy) + 1)\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, accuracy, 'b', label='Training acc')\n",
    "    plt.plot(x, val_accuracy, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "450d23fc-f536-497b-a610-a9eb3e544519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>PriceUSD</th>\n",
       "      <th>AdrActCnt</th>\n",
       "      <th>AdrBal1in100MCnt</th>\n",
       "      <th>AdrBal1in10BCnt</th>\n",
       "      <th>AdrBal1in10MCnt</th>\n",
       "      <th>AdrBal1in1BCnt</th>\n",
       "      <th>AdrBal1in1MCnt</th>\n",
       "      <th>CapMrktCurUSD</th>\n",
       "      <th>CapRealUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>FlowOutExUSD</th>\n",
       "      <th>GasUsedTx</th>\n",
       "      <th>GasUsedTxMean</th>\n",
       "      <th>HashRate</th>\n",
       "      <th>RevHashNtv</th>\n",
       "      <th>RevHashRateNtv</th>\n",
       "      <th>RevHashRateUSD</th>\n",
       "      <th>SplyAdrBalUSD1M</th>\n",
       "      <th>TxCnt</th>\n",
       "      <th>TxTfrValMedUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>1.199990</td>\n",
       "      <td>1208</td>\n",
       "      <td>9958</td>\n",
       "      <td>10267</td>\n",
       "      <td>9550</td>\n",
       "      <td>10115</td>\n",
       "      <td>8111</td>\n",
       "      <td>8.676871e+07</td>\n",
       "      <td>1.500465e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.698517e+04</td>\n",
       "      <td>376006093</td>\n",
       "      <td>130512.354391</td>\n",
       "      <td>0.096483</td>\n",
       "      <td>3.360253</td>\n",
       "      <td>290325.822770</td>\n",
       "      <td>348388.084065</td>\n",
       "      <td>1.661840e+07</td>\n",
       "      <td>2881</td>\n",
       "      <td>1.199990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-08-09</td>\n",
       "      <td>1.199990</td>\n",
       "      <td>1113</td>\n",
       "      <td>10043</td>\n",
       "      <td>10411</td>\n",
       "      <td>9573</td>\n",
       "      <td>10222</td>\n",
       "      <td>8091</td>\n",
       "      <td>8.680133e+07</td>\n",
       "      <td>1.778419e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.127113e+05</td>\n",
       "      <td>38863003</td>\n",
       "      <td>29242.289691</td>\n",
       "      <td>0.101360</td>\n",
       "      <td>3.105048</td>\n",
       "      <td>268276.120316</td>\n",
       "      <td>321928.661618</td>\n",
       "      <td>1.682678e+07</td>\n",
       "      <td>1329</td>\n",
       "      <td>15.599147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-08-10</td>\n",
       "      <td>1.199990</td>\n",
       "      <td>1430</td>\n",
       "      <td>10145</td>\n",
       "      <td>10572</td>\n",
       "      <td>9611</td>\n",
       "      <td>10348</td>\n",
       "      <td>8101</td>\n",
       "      <td>8.683471e+07</td>\n",
       "      <td>1.878138e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>2.135630e+05</td>\n",
       "      <td>74070061</td>\n",
       "      <td>36362.327442</td>\n",
       "      <td>0.111855</td>\n",
       "      <td>2.881582</td>\n",
       "      <td>248968.649994</td>\n",
       "      <td>298759.890307</td>\n",
       "      <td>1.720648e+07</td>\n",
       "      <td>2037</td>\n",
       "      <td>0.718002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-08-11</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>2697</td>\n",
       "      <td>10188</td>\n",
       "      <td>10706</td>\n",
       "      <td>9614</td>\n",
       "      <td>10429</td>\n",
       "      <td>8081</td>\n",
       "      <td>7.166698e+07</td>\n",
       "      <td>1.869114e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.752126e+05</td>\n",
       "      <td>163481740</td>\n",
       "      <td>32940.104775</td>\n",
       "      <td>0.124450</td>\n",
       "      <td>2.607691</td>\n",
       "      <td>225304.507322</td>\n",
       "      <td>223051.462249</td>\n",
       "      <td>1.551874e+07</td>\n",
       "      <td>4963</td>\n",
       "      <td>0.053993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-08-12</td>\n",
       "      <td>1.288000</td>\n",
       "      <td>1219</td>\n",
       "      <td>10296</td>\n",
       "      <td>10893</td>\n",
       "      <td>9654</td>\n",
       "      <td>10574</td>\n",
       "      <td>8105</td>\n",
       "      <td>9.327472e+07</td>\n",
       "      <td>1.983690e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.891297e+05</td>\n",
       "      <td>70102332</td>\n",
       "      <td>34431.400786</td>\n",
       "      <td>0.130915</td>\n",
       "      <td>2.422720</td>\n",
       "      <td>209322.978321</td>\n",
       "      <td>269607.996077</td>\n",
       "      <td>1.851254e+07</td>\n",
       "      <td>2036</td>\n",
       "      <td>12.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>4569.407770</td>\n",
       "      <td>606036</td>\n",
       "      <td>1166692</td>\n",
       "      <td>18202185</td>\n",
       "      <td>241239</td>\n",
       "      <td>5573039</td>\n",
       "      <td>36595</td>\n",
       "      <td>5.367033e+11</td>\n",
       "      <td>2.735353e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.029855e+10</td>\n",
       "      <td>97422476367</td>\n",
       "      <td>75542.615410</td>\n",
       "      <td>817.739849</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>18.400399</td>\n",
       "      <td>84078.925802</td>\n",
       "      <td>1.025092e+08</td>\n",
       "      <td>1289636</td>\n",
       "      <td>456.940777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>2021-11-16</td>\n",
       "      <td>4234.131465</td>\n",
       "      <td>609879</td>\n",
       "      <td>1165639</td>\n",
       "      <td>18237665</td>\n",
       "      <td>240967</td>\n",
       "      <td>5580973</td>\n",
       "      <td>36564</td>\n",
       "      <td>4.973249e+11</td>\n",
       "      <td>2.675504e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.678261e+09</td>\n",
       "      <td>96356492010</td>\n",
       "      <td>73545.984332</td>\n",
       "      <td>793.794054</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>18.962616</td>\n",
       "      <td>80290.211052</td>\n",
       "      <td>1.022489e+08</td>\n",
       "      <td>1310153</td>\n",
       "      <td>423.413146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>2021-11-17</td>\n",
       "      <td>4265.599006</td>\n",
       "      <td>695412</td>\n",
       "      <td>1167736</td>\n",
       "      <td>18217312</td>\n",
       "      <td>241192</td>\n",
       "      <td>5589438</td>\n",
       "      <td>36563</td>\n",
       "      <td>5.010266e+11</td>\n",
       "      <td>2.678047e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.282525e+09</td>\n",
       "      <td>98477697827</td>\n",
       "      <td>72772.919850</td>\n",
       "      <td>830.259240</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>17.849640</td>\n",
       "      <td>76139.406528</td>\n",
       "      <td>1.022624e+08</td>\n",
       "      <td>1353219</td>\n",
       "      <td>319.823949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>2021-11-18</td>\n",
       "      <td>3985.674373</td>\n",
       "      <td>591159</td>\n",
       "      <td>1170963</td>\n",
       "      <td>18239379</td>\n",
       "      <td>241438</td>\n",
       "      <td>5599347</td>\n",
       "      <td>36605</td>\n",
       "      <td>4.681491e+11</td>\n",
       "      <td>2.625782e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.424465e+09</td>\n",
       "      <td>98258045079</td>\n",
       "      <td>76510.060408</td>\n",
       "      <td>851.155962</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>17.527776</td>\n",
       "      <td>69860.008277</td>\n",
       "      <td>1.019504e+08</td>\n",
       "      <td>1284250</td>\n",
       "      <td>398.991334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>2021-11-19</td>\n",
       "      <td>4291.286350</td>\n",
       "      <td>609855</td>\n",
       "      <td>1173875</td>\n",
       "      <td>18249104</td>\n",
       "      <td>241822</td>\n",
       "      <td>5610275</td>\n",
       "      <td>36682</td>\n",
       "      <td>5.040554e+11</td>\n",
       "      <td>2.677075e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.341948e+09</td>\n",
       "      <td>96064983806</td>\n",
       "      <td>76497.771762</td>\n",
       "      <td>801.632454</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>17.963830</td>\n",
       "      <td>77087.939898</td>\n",
       "      <td>1.022363e+08</td>\n",
       "      <td>1255788</td>\n",
       "      <td>397.261972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2296 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     PriceUSD  AdrActCnt  AdrBal1in100MCnt  AdrBal1in10BCnt  \\\n",
       "0     2015-08-08     1.199990       1208              9958            10267   \n",
       "1     2015-08-09     1.199990       1113             10043            10411   \n",
       "2     2015-08-10     1.199990       1430             10145            10572   \n",
       "3     2015-08-11     0.990000       2697             10188            10706   \n",
       "4     2015-08-12     1.288000       1219             10296            10893   \n",
       "...          ...          ...        ...               ...              ...   \n",
       "2291  2021-11-15  4569.407770     606036           1166692         18202185   \n",
       "2292  2021-11-16  4234.131465     609879           1165639         18237665   \n",
       "2293  2021-11-17  4265.599006     695412           1167736         18217312   \n",
       "2294  2021-11-18  3985.674373     591159           1170963         18239379   \n",
       "2295  2021-11-19  4291.286350     609855           1173875         18249104   \n",
       "\n",
       "      AdrBal1in10MCnt  AdrBal1in1BCnt  AdrBal1in1MCnt  CapMrktCurUSD  \\\n",
       "0                9550           10115            8111   8.676871e+07   \n",
       "1                9573           10222            8091   8.680133e+07   \n",
       "2                9611           10348            8101   8.683471e+07   \n",
       "3                9614           10429            8081   7.166698e+07   \n",
       "4                9654           10574            8105   9.327472e+07   \n",
       "...               ...             ...             ...            ...   \n",
       "2291           241239         5573039           36595   5.367033e+11   \n",
       "2292           240967         5580973           36564   4.973249e+11   \n",
       "2293           241192         5589438           36563   5.010266e+11   \n",
       "2294           241438         5599347           36605   4.681491e+11   \n",
       "2295           241822         5610275           36682   5.040554e+11   \n",
       "\n",
       "        CapRealUSD  ...  FlowOutExUSD    GasUsedTx  GasUsedTxMean    HashRate  \\\n",
       "0     1.500465e+07  ...  1.698517e+04    376006093  130512.354391    0.096483   \n",
       "1     1.778419e+07  ...  1.127113e+05     38863003   29242.289691    0.101360   \n",
       "2     1.878138e+07  ...  2.135630e+05     74070061   36362.327442    0.111855   \n",
       "3     1.869114e+07  ...  1.752126e+05    163481740   32940.104775    0.124450   \n",
       "4     1.983690e+07  ...  1.891297e+05     70102332   34431.400786    0.130915   \n",
       "...            ...  ...           ...          ...            ...         ...   \n",
       "2291  2.735353e+11  ...  1.029855e+10  97422476367   75542.615410  817.739849   \n",
       "2292  2.675504e+11  ...  1.678261e+09  96356492010   73545.984332  793.794054   \n",
       "2293  2.678047e+11  ...  1.282525e+09  98477697827   72772.919850  830.259240   \n",
       "2294  2.625782e+11  ...  1.424465e+09  98258045079   76510.060408  851.155962   \n",
       "2295  2.677075e+11  ...  1.341948e+09  96064983806   76497.771762  801.632454   \n",
       "\n",
       "      RevHashNtv  RevHashRateNtv  RevHashRateUSD  SplyAdrBalUSD1M    TxCnt  \\\n",
       "0       3.360253   290325.822770   348388.084065     1.661840e+07     2881   \n",
       "1       3.105048   268276.120316   321928.661618     1.682678e+07     1329   \n",
       "2       2.881582   248968.649994   298759.890307     1.720648e+07     2037   \n",
       "3       2.607691   225304.507322   223051.462249     1.551874e+07     4963   \n",
       "4       2.422720   209322.978321   269607.996077     1.851254e+07     2036   \n",
       "...          ...             ...             ...              ...      ...   \n",
       "2291    0.000213       18.400399    84078.925802     1.025092e+08  1289636   \n",
       "2292    0.000219       18.962616    80290.211052     1.022489e+08  1310153   \n",
       "2293    0.000207       17.849640    76139.406528     1.022624e+08  1353219   \n",
       "2294    0.000203       17.527776    69860.008277     1.019504e+08  1284250   \n",
       "2295    0.000208       17.963830    77087.939898     1.022363e+08  1255788   \n",
       "\n",
       "      TxTfrValMedUSD  \n",
       "0           1.199990  \n",
       "1          15.599147  \n",
       "2           0.718002  \n",
       "3           0.053993  \n",
       "4          12.880000  \n",
       "...              ...  \n",
       "2291      456.940777  \n",
       "2292      423.413146  \n",
       "2293      319.823949  \n",
       "2294      398.991334  \n",
       "2295      397.261972  \n",
       "\n",
       "[2296 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/eth_clean.csv')\n",
    "df.drop(columns='Unnamed: 0', inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc417c9-6e79-45c3-8106-3fa70290ccd7",
   "metadata": {},
   "source": [
    "### 2. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d974f62-c3cf-49dd-bc48-15789057ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(df):\n",
    "    # copy from raw data\n",
    "    data = df.copy()\n",
    "\n",
    "    # drop the timestamp columns as it is not used as a predictor\n",
    "    data.drop(columns='date', inplace=True)\n",
    "\n",
    "    # ensure all data is float\n",
    "    data = data.astype(float)\n",
    "\n",
    "    # create a new feature named \"Label\": 1 means the price is up, 0 means the price is down or not changed\n",
    "    data['Label'] = 0\n",
    "\n",
    "    for i in range(len(data.index)):\n",
    "        if i == 0:\n",
    "            data['Label'][i] = 0 \n",
    "        elif data['PriceUSD'][i] > data['PriceUSD'][i-1]:\n",
    "            data['Label'][i] = 1 \n",
    "        else:\n",
    "            data['Label'][i] = 0 \n",
    "            \n",
    "    # normalize the dataset\n",
    "    scaler = MinMaxScaler()\n",
    "    np_data_scaled = scaler.fit_transform(data.values)\n",
    "\n",
    "    # scale one feature for reversion purpose later\n",
    "    scaler_pred = MinMaxScaler()\n",
    "    df_Label = pd.DataFrame(data['Label'])\n",
    "    np_Label_scaled = scaler_pred.fit_transform(df_Label)\n",
    "    \n",
    "    return data, scaler, scaler_pred, np_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7b9dde-8978-42ab-8c90-f702863009ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, scaler, scaler_pred, np_data_scaled = data_processing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1f4014-32e1-44f5-a7f3-29724ac9d36f",
   "metadata": {},
   "source": [
    "### 3. Data Transformation\n",
    "\n",
    "- The first 90% of the data is used in training the model, and the last 10% will be used to test the model.\n",
    "- The RNN-LSTM needs data with the format of [samples, time steps, features], so let's transform data from [num rows x num features] to N samples, sequence_length time steps per sample, and number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86867b66-2e5c-4937-b4f5-3bd4b7659fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def data_transformation(data, sequence_length, np_data_scaled, index_target):\n",
    "def data_transformation(sequence_length, np_data_scaled, index_target):\n",
    "    \n",
    "    # Split the training data into train and train data sets\n",
    "    train_data_len = math.ceil(np_data_scaled.shape[0] * 0.9)\n",
    "\n",
    "    # Create the training and test data\n",
    "    train_data = np_data_scaled[0:train_data_len, :]\n",
    "    test_data = np_data_scaled[train_data_len - sequence_length:, :]\n",
    "\n",
    "    # Generate training data and test data\n",
    "    x_train, y_train = partition_dataset(sequence_length, train_data, index_target)\n",
    "    x_test, y_test = partition_dataset(sequence_length, test_data, index_target)\n",
    "\n",
    "    # Print the shapes:\n",
    "    print('X_train shape: ', x_train.shape)\n",
    "    print('y_train shape: ', y_train.shape)\n",
    "    print('X_test shape: ', x_test.shape)\n",
    "    print('y_test shape: ', y_test.shape)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "625a270a-99f3-4c68-9934-8492bd6ea6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (2060, 7, 25)\n",
      "y_train shape:  (2060,)\n",
      "X_test shape:  (229, 7, 25)\n",
      "y_test shape:  (229,)\n"
     ]
    }
   ],
   "source": [
    "# Data transformation\n",
    "sequence_length = 7\n",
    "x_train, y_train, x_test, y_test = data_transformation(sequence_length, np_data_scaled, data.columns.get_loc(\"Label\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520e610b-4cb8-47fe-9b7c-07f0d7d96cc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Creating the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "057cd699-9ff4-449d-8508-c631b7a4f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_train):\n",
    "    \n",
    "    \"\"\"\n",
    "    This model includes:\n",
    "    - Two LSTM layers with number of neurons is window length * number of features, the input shape is (x_train.shape[1], x_train.shape[2])\n",
    "    - One fully connect layer with 50 neurons\n",
    "    - The final dense layer that outputs the predicted value\n",
    "    - Adam Optimizer\n",
    "    - Set the loss as the mean_squarred_error\n",
    "    \n",
    "    \"\"\"\n",
    "    # initial the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Model with n_neurons = window length * number of features\n",
    "    n_neurons = x_train.shape[1] * x_train.shape[2]\n",
    "\n",
    "    model.add(LSTM(n_neurons, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2]))) \n",
    "    model.add(LSTM(n_neurons, return_sequences=False))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48883e1-bb74-4b44-af77-d6532f198eba",
   "metadata": {},
   "source": [
    "### 5. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd5c4d-742c-431c-b664-e7309dcd111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 03:29:07.672175: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 7, 175)            140700    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 175)               245700    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                8800      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 395,251\n",
      "Trainable params: 395,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 03:29:08.098223: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 5s 37ms/step - loss: 0.6951 - accuracy: 0.5068 - val_loss: 0.7056 - val_accuracy: 0.4498\n",
      "Epoch 2/50\n",
      "65/65 [==============================] - 2s 28ms/step - loss: 0.6939 - accuracy: 0.4922 - val_loss: 0.6917 - val_accuracy: 0.5502\n",
      "Epoch 3/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 0.6926 - accuracy: 0.5141 - val_loss: 0.6913 - val_accuracy: 0.5502\n",
      "Epoch 4/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 0.6938 - accuracy: 0.5180 - val_loss: 0.6926 - val_accuracy: 0.5459\n",
      "Epoch 5/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 0.6925 - accuracy: 0.5180 - val_loss: 0.6893 - val_accuracy: 0.5502\n",
      "Epoch 6/50\n",
      "65/65 [==============================] - 2s 30ms/step - loss: 0.6925 - accuracy: 0.5092 - val_loss: 0.6889 - val_accuracy: 0.5502\n",
      "Epoch 7/50\n",
      "65/65 [==============================] - 2s 31ms/step - loss: 0.6926 - accuracy: 0.5083 - val_loss: 0.7015 - val_accuracy: 0.5502\n",
      "Epoch 8/50\n",
      "65/65 [==============================] - 2s 30ms/step - loss: 0.6937 - accuracy: 0.5049 - val_loss: 0.6901 - val_accuracy: 0.5502\n",
      "Epoch 9/50\n",
      "65/65 [==============================] - 2s 30ms/step - loss: 0.6923 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.5502\n",
      "Epoch 10/50\n",
      "65/65 [==============================] - 2s 32ms/step - loss: 0.6933 - accuracy: 0.5180 - val_loss: 0.6909 - val_accuracy: 0.5808\n",
      "Epoch 11/50\n",
      "65/65 [==============================] - 2s 28ms/step - loss: 0.6925 - accuracy: 0.5228 - val_loss: 0.6879 - val_accuracy: 0.5502\n",
      "Epoch 12/50\n",
      "65/65 [==============================] - 2s 28ms/step - loss: 0.6915 - accuracy: 0.5262 - val_loss: 0.6843 - val_accuracy: 0.5502\n",
      "Epoch 13/50\n",
      "65/65 [==============================] - 2s 29ms/step - loss: 0.6900 - accuracy: 0.5175 - val_loss: 0.6956 - val_accuracy: 0.4672\n",
      "Epoch 14/50\n",
      "65/65 [==============================] - 2s 29ms/step - loss: 0.6931 - accuracy: 0.4995 - val_loss: 0.6925 - val_accuracy: 0.5197\n",
      "Epoch 15/50\n",
      "65/65 [==============================] - 2s 30ms/step - loss: 0.6924 - accuracy: 0.5102 - val_loss: 0.6954 - val_accuracy: 0.4716\n",
      "Epoch 16/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 0.6933 - accuracy: 0.5136 - val_loss: 0.6898 - val_accuracy: 0.5502\n",
      "Epoch 17/50\n",
      "65/65 [==============================] - 2s 28ms/step - loss: 0.6912 - accuracy: 0.5233 - val_loss: 0.6879 - val_accuracy: 0.5502\n",
      "Epoch 18/50\n",
      "65/65 [==============================] - 2s 29ms/step - loss: 0.6912 - accuracy: 0.5316 - val_loss: 0.6919 - val_accuracy: 0.5502\n",
      "Epoch 19/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 0.6910 - accuracy: 0.5252 - val_loss: 0.6875 - val_accuracy: 0.5502\n",
      "Epoch 20/50\n",
      "65/65 [==============================] - 2s 29ms/step - loss: 0.6904 - accuracy: 0.5204 - val_loss: 0.6923 - val_accuracy: 0.5284\n",
      "Epoch 21/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 0.6896 - accuracy: 0.5369 - val_loss: 0.6866 - val_accuracy: 0.5502\n",
      "Epoch 22/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 0.6880 - accuracy: 0.5335 - val_loss: 0.6870 - val_accuracy: 0.5546\n",
      "Epoch 23/50\n",
      "65/65 [==============================] - 2s 28ms/step - loss: 0.6888 - accuracy: 0.5383 - val_loss: 0.6878 - val_accuracy: 0.5590\n",
      "Epoch 24/50\n",
      "65/65 [==============================] - 2s 28ms/step - loss: 0.6871 - accuracy: 0.5466 - val_loss: 0.6880 - val_accuracy: 0.5153\n",
      "Epoch 25/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 0.6883 - accuracy: 0.5335 - val_loss: 0.6874 - val_accuracy: 0.5502\n",
      "Epoch 26/50\n",
      "65/65 [==============================] - 2s 28ms/step - loss: 0.6869 - accuracy: 0.5466 - val_loss: 0.6856 - val_accuracy: 0.5764\n",
      "Epoch 27/50\n",
      "59/65 [==========================>...] - ETA: 0s - loss: 0.6884 - accuracy: 0.5445"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "model = model(x_train)\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3544654-1ad8-4cde-8657-c8d0a89093b6",
   "metadata": {},
   "source": [
    "### 6. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f21a45-5057-405b-8a6a-c70cf0a4de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test, scaler_pred):\n",
    "\n",
    "    # Predict the Ether price\n",
    "    y_pred_scaled = model.predict(x_test)\n",
    "        \n",
    "    # Unscale the predicted values\n",
    "    y_pred = scaler_pred.inverse_transform(y_pred_scaled)\n",
    "    y_test_unscaled = scaler_pred.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    #y_pred_classes=tf.argmax(y_pred,axis=-1)\n",
    "    y_pred_classes=np.round(y_pred,0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    binary_classifier_metrics(y_test, y_pred_classes)\n",
    "    \n",
    "    return y_test_unscaled, y_pred_classes, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600671c4-563a-4bdf-aaa1-58ba6e434a5c",
   "metadata": {},
   "source": [
    "#### Plot training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7677deb8-4f68-4d86-8ed7-78af8a65931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b132de3-a3f8-41f6-aa20-41b037712982",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c08368b-a6cd-4b42-b5e8-7a451b8a88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_unscaled, y_pred_classes, y_pred = evaluate_model(model, x_test, y_test, scaler_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
