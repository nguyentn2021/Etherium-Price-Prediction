{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896ac136-1273-4b7f-9f48-91aaaedb70cb",
   "metadata": {},
   "source": [
    "## Predict Ethereum price using Recurrent Neural Networks (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc35df7c-92c8-42fa-a8c4-f7679852caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary packages\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping \n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.backend import clear_session\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98afaf-295e-43d9-83b1-bd0c8e4d7be4",
   "metadata": {},
   "source": [
    "##### First of all, I define some functions we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814bc599-458c-46ff-b323-9eeb2d784ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_dataset(window_length, data, index_target):\n",
    "    \"\"\"\n",
    "    The LSTM needs data with the format of [samples, time steps, features], \n",
    "    so we create N samples, window_length time steps per sample, and number of features\n",
    "    \"\"\"\n",
    "    x, y = [], []\n",
    "    data_len = data.shape[0]\n",
    "    for i in range(window_length, data_len):\n",
    "        x.append(data[i-window_length:i,:])\n",
    "        y.append(data[i, index_target])\n",
    "    \n",
    "    # Convert the x and y to numpy arrays\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a7f1fb-40e7-4d8a-b7af-9f6665d25405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_metrics(y_test, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    Define evaluation metrics for regression problem\n",
    "    Parameters: y_test: true values\n",
    "                y_pred: predicted values\n",
    "    \"\"\"\n",
    "    \n",
    "    print('R2 Score: ', r2_score(y_test, y_pred))\n",
    "    print('Mean Absolute Error: ', mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error: ', mean_squared_error(y_test, y_pred))\n",
    "    MDAPE = np.mean((np.abs(np.subtract(y_test, y_pred)/ y_test)) ) * 100\n",
    "    print(f'Mean Absolute Percentage Error: {np.round(MDAPE, 2)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86f4f18a-3ccd-486a-aa94-9967f66ca475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_accuracy_loss(history):\n",
    "\n",
    "    \"\"\" Plot training & testing loss values \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20, 10), sharex=True)\n",
    "    plt.plot(history.history[\"loss\"])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(\"Model loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(epochs))\n",
    "    plt.legend([\"Training\", \"Testing\"], loc=\"upper left\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3510feac-6fa8-4989-979a-f5e80d38d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_predicted(original, predictions, title):\n",
    "     \n",
    "    \"\"\" Visualize actual and predicted price \"\"\"\n",
    "    \n",
    "    ax = sns.lineplot(x=original.index, y=original[0], label=\"Real Price\", color='royalblue',linewidth=2)\n",
    "    ax = sns.lineplot(x=predictions.index, y=predictions[0], label=\"Predicted Price\", color='tomato',linewidth=2)\n",
    "    ax.set_title(title, size = 20)\n",
    "    ax.set_xlabel(\"Date\", size = 16)\n",
    "    ax.set_ylabel(\"Price (USD)\", size = 16)\n",
    "    ax.set_xticklabels('', size=16);\n",
    "    plt.grid()\n",
    "    set_size(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9775ec2e-23de-4d53-a1a0-62db2dda82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_size(w, h, ax=None):\n",
    "    \"\"\" w, h: width, height in inches \"\"\"\n",
    "    if not ax: ax=plt.gca()\n",
    "    l = ax.figure.subplotpars.left\n",
    "    r = ax.figure.subplotpars.right\n",
    "    t = ax.figure.subplotpars.top\n",
    "    b = ax.figure.subplotpars.bottom\n",
    "    figw = float(w)/(r-l)\n",
    "    figh = float(h)/(t-b)\n",
    "    ax.figure.set_size_inches(figw, figh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c962111-b32e-43c3-b451-147a40b178cc",
   "metadata": {},
   "source": [
    "### 1. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "450d23fc-f536-497b-a610-a9eb3e544519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>PriceUSD</th>\n",
       "      <th>AdrActCnt</th>\n",
       "      <th>AdrBal1in100MCnt</th>\n",
       "      <th>AdrBal1in10BCnt</th>\n",
       "      <th>AdrBal1in10MCnt</th>\n",
       "      <th>AdrBal1in1BCnt</th>\n",
       "      <th>AdrBal1in1MCnt</th>\n",
       "      <th>CapMrktCurUSD</th>\n",
       "      <th>CapRealUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>FlowOutExUSD</th>\n",
       "      <th>GasUsedTx</th>\n",
       "      <th>GasUsedTxMean</th>\n",
       "      <th>HashRate</th>\n",
       "      <th>RevHashNtv</th>\n",
       "      <th>RevHashRateNtv</th>\n",
       "      <th>RevHashRateUSD</th>\n",
       "      <th>SplyAdrBalUSD1M</th>\n",
       "      <th>TxCnt</th>\n",
       "      <th>TxTfrValMedUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>1.199990</td>\n",
       "      <td>1208</td>\n",
       "      <td>9958</td>\n",
       "      <td>10267</td>\n",
       "      <td>9550</td>\n",
       "      <td>10115</td>\n",
       "      <td>8111</td>\n",
       "      <td>8.676871e+07</td>\n",
       "      <td>1.500465e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.698517e+04</td>\n",
       "      <td>376006093</td>\n",
       "      <td>130512.354391</td>\n",
       "      <td>0.096483</td>\n",
       "      <td>3.360253</td>\n",
       "      <td>290325.822770</td>\n",
       "      <td>348388.084065</td>\n",
       "      <td>1.661840e+07</td>\n",
       "      <td>2881</td>\n",
       "      <td>1.199990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-08-09</td>\n",
       "      <td>1.199990</td>\n",
       "      <td>1113</td>\n",
       "      <td>10043</td>\n",
       "      <td>10411</td>\n",
       "      <td>9573</td>\n",
       "      <td>10222</td>\n",
       "      <td>8091</td>\n",
       "      <td>8.680133e+07</td>\n",
       "      <td>1.778419e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.127113e+05</td>\n",
       "      <td>38863003</td>\n",
       "      <td>29242.289691</td>\n",
       "      <td>0.101360</td>\n",
       "      <td>3.105048</td>\n",
       "      <td>268276.120316</td>\n",
       "      <td>321928.661618</td>\n",
       "      <td>1.682678e+07</td>\n",
       "      <td>1329</td>\n",
       "      <td>15.599147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-08-10</td>\n",
       "      <td>1.199990</td>\n",
       "      <td>1430</td>\n",
       "      <td>10145</td>\n",
       "      <td>10572</td>\n",
       "      <td>9611</td>\n",
       "      <td>10348</td>\n",
       "      <td>8101</td>\n",
       "      <td>8.683471e+07</td>\n",
       "      <td>1.878138e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>2.135630e+05</td>\n",
       "      <td>74070061</td>\n",
       "      <td>36362.327442</td>\n",
       "      <td>0.111855</td>\n",
       "      <td>2.881582</td>\n",
       "      <td>248968.649994</td>\n",
       "      <td>298759.890307</td>\n",
       "      <td>1.720648e+07</td>\n",
       "      <td>2037</td>\n",
       "      <td>0.718002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-08-11</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>2697</td>\n",
       "      <td>10188</td>\n",
       "      <td>10706</td>\n",
       "      <td>9614</td>\n",
       "      <td>10429</td>\n",
       "      <td>8081</td>\n",
       "      <td>7.166698e+07</td>\n",
       "      <td>1.869114e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.752126e+05</td>\n",
       "      <td>163481740</td>\n",
       "      <td>32940.104775</td>\n",
       "      <td>0.124450</td>\n",
       "      <td>2.607691</td>\n",
       "      <td>225304.507322</td>\n",
       "      <td>223051.462249</td>\n",
       "      <td>1.551874e+07</td>\n",
       "      <td>4963</td>\n",
       "      <td>0.053993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-08-12</td>\n",
       "      <td>1.288000</td>\n",
       "      <td>1219</td>\n",
       "      <td>10296</td>\n",
       "      <td>10893</td>\n",
       "      <td>9654</td>\n",
       "      <td>10574</td>\n",
       "      <td>8105</td>\n",
       "      <td>9.327472e+07</td>\n",
       "      <td>1.983690e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.891297e+05</td>\n",
       "      <td>70102332</td>\n",
       "      <td>34431.400786</td>\n",
       "      <td>0.130915</td>\n",
       "      <td>2.422720</td>\n",
       "      <td>209322.978321</td>\n",
       "      <td>269607.996077</td>\n",
       "      <td>1.851254e+07</td>\n",
       "      <td>2036</td>\n",
       "      <td>12.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>4569.407770</td>\n",
       "      <td>606036</td>\n",
       "      <td>1166692</td>\n",
       "      <td>18202185</td>\n",
       "      <td>241239</td>\n",
       "      <td>5573039</td>\n",
       "      <td>36595</td>\n",
       "      <td>5.367033e+11</td>\n",
       "      <td>2.735353e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.029855e+10</td>\n",
       "      <td>97422476367</td>\n",
       "      <td>75542.615410</td>\n",
       "      <td>817.739849</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>18.400399</td>\n",
       "      <td>84078.925802</td>\n",
       "      <td>1.025092e+08</td>\n",
       "      <td>1289636</td>\n",
       "      <td>456.940777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>2021-11-16</td>\n",
       "      <td>4234.131465</td>\n",
       "      <td>609879</td>\n",
       "      <td>1165639</td>\n",
       "      <td>18237665</td>\n",
       "      <td>240967</td>\n",
       "      <td>5580973</td>\n",
       "      <td>36564</td>\n",
       "      <td>4.973249e+11</td>\n",
       "      <td>2.675504e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.678261e+09</td>\n",
       "      <td>96356492010</td>\n",
       "      <td>73545.984332</td>\n",
       "      <td>793.794054</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>18.962616</td>\n",
       "      <td>80290.211052</td>\n",
       "      <td>1.022489e+08</td>\n",
       "      <td>1310153</td>\n",
       "      <td>423.413146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>2021-11-17</td>\n",
       "      <td>4265.599006</td>\n",
       "      <td>695412</td>\n",
       "      <td>1167736</td>\n",
       "      <td>18217312</td>\n",
       "      <td>241192</td>\n",
       "      <td>5589438</td>\n",
       "      <td>36563</td>\n",
       "      <td>5.010266e+11</td>\n",
       "      <td>2.678047e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.282525e+09</td>\n",
       "      <td>98477697827</td>\n",
       "      <td>72772.919850</td>\n",
       "      <td>830.259240</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>17.849640</td>\n",
       "      <td>76139.406528</td>\n",
       "      <td>1.022624e+08</td>\n",
       "      <td>1353219</td>\n",
       "      <td>319.823949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>2021-11-18</td>\n",
       "      <td>3985.674373</td>\n",
       "      <td>591159</td>\n",
       "      <td>1170963</td>\n",
       "      <td>18239379</td>\n",
       "      <td>241438</td>\n",
       "      <td>5599347</td>\n",
       "      <td>36605</td>\n",
       "      <td>4.681491e+11</td>\n",
       "      <td>2.625782e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.424465e+09</td>\n",
       "      <td>98258045079</td>\n",
       "      <td>76510.060408</td>\n",
       "      <td>851.155962</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>17.527776</td>\n",
       "      <td>69860.008277</td>\n",
       "      <td>1.019504e+08</td>\n",
       "      <td>1284250</td>\n",
       "      <td>398.991334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>2021-11-19</td>\n",
       "      <td>4291.286350</td>\n",
       "      <td>609855</td>\n",
       "      <td>1173875</td>\n",
       "      <td>18249104</td>\n",
       "      <td>241822</td>\n",
       "      <td>5610275</td>\n",
       "      <td>36682</td>\n",
       "      <td>5.040554e+11</td>\n",
       "      <td>2.677075e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.341948e+09</td>\n",
       "      <td>96064983806</td>\n",
       "      <td>76497.771762</td>\n",
       "      <td>801.632454</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>17.963830</td>\n",
       "      <td>77087.939898</td>\n",
       "      <td>1.022363e+08</td>\n",
       "      <td>1255788</td>\n",
       "      <td>397.261972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2296 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     PriceUSD  AdrActCnt  AdrBal1in100MCnt  AdrBal1in10BCnt  \\\n",
       "0     2015-08-08     1.199990       1208              9958            10267   \n",
       "1     2015-08-09     1.199990       1113             10043            10411   \n",
       "2     2015-08-10     1.199990       1430             10145            10572   \n",
       "3     2015-08-11     0.990000       2697             10188            10706   \n",
       "4     2015-08-12     1.288000       1219             10296            10893   \n",
       "...          ...          ...        ...               ...              ...   \n",
       "2291  2021-11-15  4569.407770     606036           1166692         18202185   \n",
       "2292  2021-11-16  4234.131465     609879           1165639         18237665   \n",
       "2293  2021-11-17  4265.599006     695412           1167736         18217312   \n",
       "2294  2021-11-18  3985.674373     591159           1170963         18239379   \n",
       "2295  2021-11-19  4291.286350     609855           1173875         18249104   \n",
       "\n",
       "      AdrBal1in10MCnt  AdrBal1in1BCnt  AdrBal1in1MCnt  CapMrktCurUSD  \\\n",
       "0                9550           10115            8111   8.676871e+07   \n",
       "1                9573           10222            8091   8.680133e+07   \n",
       "2                9611           10348            8101   8.683471e+07   \n",
       "3                9614           10429            8081   7.166698e+07   \n",
       "4                9654           10574            8105   9.327472e+07   \n",
       "...               ...             ...             ...            ...   \n",
       "2291           241239         5573039           36595   5.367033e+11   \n",
       "2292           240967         5580973           36564   4.973249e+11   \n",
       "2293           241192         5589438           36563   5.010266e+11   \n",
       "2294           241438         5599347           36605   4.681491e+11   \n",
       "2295           241822         5610275           36682   5.040554e+11   \n",
       "\n",
       "        CapRealUSD  ...  FlowOutExUSD    GasUsedTx  GasUsedTxMean    HashRate  \\\n",
       "0     1.500465e+07  ...  1.698517e+04    376006093  130512.354391    0.096483   \n",
       "1     1.778419e+07  ...  1.127113e+05     38863003   29242.289691    0.101360   \n",
       "2     1.878138e+07  ...  2.135630e+05     74070061   36362.327442    0.111855   \n",
       "3     1.869114e+07  ...  1.752126e+05    163481740   32940.104775    0.124450   \n",
       "4     1.983690e+07  ...  1.891297e+05     70102332   34431.400786    0.130915   \n",
       "...            ...  ...           ...          ...            ...         ...   \n",
       "2291  2.735353e+11  ...  1.029855e+10  97422476367   75542.615410  817.739849   \n",
       "2292  2.675504e+11  ...  1.678261e+09  96356492010   73545.984332  793.794054   \n",
       "2293  2.678047e+11  ...  1.282525e+09  98477697827   72772.919850  830.259240   \n",
       "2294  2.625782e+11  ...  1.424465e+09  98258045079   76510.060408  851.155962   \n",
       "2295  2.677075e+11  ...  1.341948e+09  96064983806   76497.771762  801.632454   \n",
       "\n",
       "      RevHashNtv  RevHashRateNtv  RevHashRateUSD  SplyAdrBalUSD1M    TxCnt  \\\n",
       "0       3.360253   290325.822770   348388.084065     1.661840e+07     2881   \n",
       "1       3.105048   268276.120316   321928.661618     1.682678e+07     1329   \n",
       "2       2.881582   248968.649994   298759.890307     1.720648e+07     2037   \n",
       "3       2.607691   225304.507322   223051.462249     1.551874e+07     4963   \n",
       "4       2.422720   209322.978321   269607.996077     1.851254e+07     2036   \n",
       "...          ...             ...             ...              ...      ...   \n",
       "2291    0.000213       18.400399    84078.925802     1.025092e+08  1289636   \n",
       "2292    0.000219       18.962616    80290.211052     1.022489e+08  1310153   \n",
       "2293    0.000207       17.849640    76139.406528     1.022624e+08  1353219   \n",
       "2294    0.000203       17.527776    69860.008277     1.019504e+08  1284250   \n",
       "2295    0.000208       17.963830    77087.939898     1.022363e+08  1255788   \n",
       "\n",
       "      TxTfrValMedUSD  \n",
       "0           1.199990  \n",
       "1          15.599147  \n",
       "2           0.718002  \n",
       "3           0.053993  \n",
       "4          12.880000  \n",
       "...              ...  \n",
       "2291      456.940777  \n",
       "2292      423.413146  \n",
       "2293      319.823949  \n",
       "2294      398.991334  \n",
       "2295      397.261972  \n",
       "\n",
       "[2296 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/eth_clean.csv')\n",
    "df.drop(columns='Unnamed: 0', inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc417c9-6e79-45c3-8106-3fa70290ccd7",
   "metadata": {},
   "source": [
    "### 2. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d974f62-c3cf-49dd-bc48-15789057ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(df):\n",
    "    # copy from raw data\n",
    "    data = df.copy()\n",
    "\n",
    "    # drop the timestamp columns as it is not used as a predictor\n",
    "    data.drop(columns='date', inplace=True)\n",
    "\n",
    "    # ensure all data is float\n",
    "    data = data.astype(float)\n",
    "\n",
    "    # normalize the dataset\n",
    "    scaler = MinMaxScaler()\n",
    "    np_data_scaled = scaler.fit_transform(data.values)\n",
    "\n",
    "    # scale one feature for reversion purpose later\n",
    "    scaler_pred = MinMaxScaler()\n",
    "    df_PriceUSD = pd.DataFrame(data['PriceUSD'])\n",
    "    np_PriceUSD_scaled = scaler_pred.fit_transform(df_PriceUSD)\n",
    "    \n",
    "    return data, scaler, scaler_pred, np_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf7b9dde-8978-42ab-8c90-f702863009ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, scaler, scaler_pred, np_data_scaled = data_processing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1f4014-32e1-44f5-a7f3-29724ac9d36f",
   "metadata": {},
   "source": [
    "### 3. Data Transformation\n",
    "\n",
    "- The first 80% of the data is used in training the model, and the last 20% will be used to test the model.\n",
    "- The RNN-LSTM needs data with the format of [samples, time steps, features], so let's transform data from [num rows x num features] to N samples, sequence_length time steps per sample, and number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86867b66-2e5c-4937-b4f5-3bd4b7659fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformation(data, sequence_length, np_data_scaled, index_target):\n",
    "    \n",
    "    # Split the training data into train and train data sets\n",
    "    train_data_len = math.ceil(np_data_scaled.shape[0] * 0.9)\n",
    "\n",
    "    # Create the training and test data\n",
    "    train_data = np_data_scaled[0:train_data_len, :]\n",
    "    test_data = np_data_scaled[train_data_len - sequence_length:, :]\n",
    "\n",
    "    # Generate training data and test data\n",
    "    x_train, y_train = partition_dataset(sequence_length, train_data, index_target)\n",
    "    x_test, y_test = partition_dataset(sequence_length, test_data, index_target)\n",
    "\n",
    "    # Print the shapes:\n",
    "    print('X_train shape: ', x_train.shape)\n",
    "    print('y_train shape: ', y_train.shape)\n",
    "    print('X_test shape: ', x_test.shape)\n",
    "    print('y_test shape: ', y_test.shape)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "625a270a-99f3-4c68-9934-8492bd6ea6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (2060, 7, 24)\n",
      "y_train shape:  (2060,)\n",
      "X_test shape:  (229, 7, 24)\n",
      "y_test shape:  (229,)\n"
     ]
    }
   ],
   "source": [
    "# Data transformation\n",
    "sequence_length = 7\n",
    "x_train, y_train, x_test, y_test = data_transformation(data, sequence_length, np_data_scaled, data.columns.get_loc(\"PriceUSD\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520e610b-4cb8-47fe-9b7c-07f0d7d96cc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Creating the LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3344f201-0690-40af-99b8-9add08711c7a",
   "metadata": {},
   "source": [
    "Here I create two models for the testing purpose to see which one is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "057cd699-9ff4-449d-8508-c631b7a4f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1(x_train):\n",
    "    \n",
    "    \"\"\"\n",
    "    Model 1:\n",
    "    - Two LSTM layers with number of neurons is window length * number of features, the input shape is (x_train.shape[1], x_train.shape[2])\n",
    "    - One fully connect layer with 50 neurons\n",
    "    - The final dense layer that outputs the predicted value\n",
    "    - Adam Optimizer\n",
    "    - Set the loss as the mean_squarred_error\n",
    "    \n",
    "    \"\"\"\n",
    "    # initial the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Model with n_neurons = window length * number of features\n",
    "    n_neurons = x_train.shape[1] * x_train.shape[2]\n",
    "\n",
    "    model.add(LSTM(n_neurons, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2]))) \n",
    "    model.add(LSTM(n_neurons, return_sequences=False))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d44bf3fa-2b7b-4098-88f0-1aa3496b61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2(x_train, dropout):\n",
    "    \n",
    "    \"\"\"\n",
    "    Model 2 includes:\n",
    "    - three LSTM layers, with number of neurons is window length * number of features, the input shape is (x_train.shape[1], x_train.shape[2])\n",
    "    - Three dropout layers defining after each LSTM layer\n",
    "    - One fully connect layer with 50 neurons \n",
    "    - The final dense layer that outputs the predicted value\n",
    "    - Adam Optimizer\n",
    "    - Set the loss as the mean_squarred_error\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Configure the neural network model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Model with n_neurons = window length * number of features\n",
    "    n_neurons = x_train.shape[1] * x_train.shape[2]\n",
    "\n",
    "    model.add(LSTM(n_neurons, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2]))) \n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(LSTM(n_neurons, return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(LSTM(n_neurons, return_sequences=False))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(50))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48883e1-bb74-4b44-af77-d6532f198eba",
   "metadata": {},
   "source": [
    "### 5. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80c7b5f5-28b5-4887-bc4a-9a8093b52055",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca1dd6e-0f4d-4713-b2a8-ff0ae8403d5b",
   "metadata": {},
   "source": [
    "##### Model 1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3fd5c4d-742c-431c-b664-e7309dcd111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 17:40:13.799032: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 7, 168)            129696    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 168)               226464    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                8450      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 364,661\n",
      "Trainable params: 364,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 17:40:14.274492: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 5s 36ms/step - loss: 0.0036 - val_loss: 0.0160\n",
      "Epoch 2/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 2.2761e-04 - val_loss: 0.0074\n",
      "Epoch 3/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 1.6931e-04 - val_loss: 0.0091\n",
      "Epoch 4/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 1.4703e-04 - val_loss: 0.0064\n",
      "Epoch 5/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 1.5353e-04 - val_loss: 0.0038\n",
      "Epoch 6/50\n",
      "65/65 [==============================] - 2s 32ms/step - loss: 1.5132e-04 - val_loss: 0.0040\n",
      "Epoch 7/50\n",
      "65/65 [==============================] - 2s 30ms/step - loss: 1.0885e-04 - val_loss: 0.0044\n",
      "Epoch 8/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 1.1446e-04 - val_loss: 0.0039\n",
      "Epoch 9/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 1.2079e-04 - val_loss: 0.0048\n",
      "Epoch 10/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 1.5490e-04 - val_loss: 0.0037\n",
      "Epoch 11/50\n",
      "65/65 [==============================] - 2s 30ms/step - loss: 1.6797e-04 - val_loss: 0.0039\n",
      "Epoch 12/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 1.0576e-04 - val_loss: 0.0037\n",
      "Epoch 13/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 9.3238e-05 - val_loss: 0.0036\n",
      "Epoch 14/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 1.0334e-04 - val_loss: 0.0046\n",
      "Epoch 15/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 8.4774e-05 - val_loss: 0.0041\n",
      "Epoch 16/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 1.1351e-04 - val_loss: 0.0064\n",
      "Epoch 17/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 9.6874e-05 - val_loss: 0.0032\n",
      "Epoch 18/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 8.2511e-05 - val_loss: 0.0037\n",
      "Epoch 19/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 9.5324e-05 - val_loss: 0.0052\n",
      "Epoch 20/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 8.7799e-05 - val_loss: 0.0054\n",
      "Epoch 21/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 9.5490e-05 - val_loss: 0.0029\n",
      "Epoch 22/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 9.0009e-05 - val_loss: 0.0047\n",
      "Epoch 23/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 8.3938e-05 - val_loss: 0.0040\n",
      "Epoch 24/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 1.7595e-04 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 7.6040e-05 - val_loss: 0.0029\n",
      "Epoch 26/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 7.4159e-05 - val_loss: 0.0043\n",
      "Epoch 27/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 6.9325e-05 - val_loss: 0.0032\n",
      "Epoch 28/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 8.7280e-05 - val_loss: 0.0024\n",
      "Epoch 29/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 7.3910e-05 - val_loss: 0.0024\n",
      "Epoch 30/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 8.6245e-05 - val_loss: 0.0026\n",
      "Epoch 31/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 6.7888e-05 - val_loss: 0.0050\n",
      "Epoch 32/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 7.2856e-05 - val_loss: 0.0038\n",
      "Epoch 33/50\n",
      "65/65 [==============================] - 2s 30ms/step - loss: 7.3624e-05 - val_loss: 0.0047\n",
      "Epoch 34/50\n",
      "65/65 [==============================] - 2s 28ms/step - loss: 7.5776e-05 - val_loss: 0.0023\n",
      "Epoch 35/50\n",
      "65/65 [==============================] - 2s 28ms/step - loss: 5.4474e-05 - val_loss: 0.0068\n",
      "Epoch 36/50\n",
      "65/65 [==============================] - 2s 28ms/step - loss: 6.6794e-05 - val_loss: 0.0032\n",
      "Epoch 37/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 6.2509e-05 - val_loss: 0.0024\n",
      "Epoch 38/50\n",
      "65/65 [==============================] - 2s 29ms/step - loss: 5.6535e-05 - val_loss: 0.0030\n",
      "Epoch 39/50\n",
      "65/65 [==============================] - 2s 28ms/step - loss: 4.2550e-05 - val_loss: 0.0046\n",
      "Epoch 40/50\n",
      "65/65 [==============================] - 2s 29ms/step - loss: 6.2091e-05 - val_loss: 0.0019\n",
      "Epoch 41/50\n",
      "65/65 [==============================] - 2s 29ms/step - loss: 6.2023e-05 - val_loss: 0.0018\n",
      "Epoch 42/50\n",
      "65/65 [==============================] - 2s 31ms/step - loss: 5.6786e-05 - val_loss: 0.0019\n",
      "Epoch 43/50\n",
      "65/65 [==============================] - 2s 30ms/step - loss: 6.0718e-05 - val_loss: 0.0018\n",
      "Epoch 44/50\n",
      "65/65 [==============================] - 2s 29ms/step - loss: 4.9523e-05 - val_loss: 0.0023\n",
      "Epoch 45/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 4.0715e-05 - val_loss: 0.0022\n",
      "Epoch 46/50\n",
      "65/65 [==============================] - 2s 28ms/step - loss: 5.2328e-05 - val_loss: 0.0018\n",
      "Epoch 47/50\n",
      "65/65 [==============================] - 2s 28ms/step - loss: 4.9337e-05 - val_loss: 0.0020\n",
      "Epoch 48/50\n",
      "65/65 [==============================] - 2s 28ms/step - loss: 5.3505e-05 - val_loss: 0.0020\n",
      "Epoch 49/50\n",
      "65/65 [==============================] - 2s 27ms/step - loss: 4.9263e-05 - val_loss: 0.0020\n",
      "Epoch 50/50\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 4.8355e-05 - val_loss: 0.0016\n"
     ]
    }
   ],
   "source": [
    "model_1 = model_1(x_train)\n",
    "history_1 = model_1.fit(x_train, y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c296d8-cc72-48be-887b-36f4e3add58d",
   "metadata": {},
   "source": [
    "##### Model 2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba1d84-c766-42ce-9252-7243580097e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 7, 168)            129696    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 7, 168)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 7, 168)            226464    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 168)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 168)               226464    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 168)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                8450      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 591,125\n",
      "Trainable params: 591,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "65/65 [==============================] - 8s 59ms/step - loss: 0.0011 - val_loss: 0.0267\n",
      "Epoch 2/50\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 3.6975e-04 - val_loss: 0.0098\n",
      "Epoch 3/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 3.1974e-04 - val_loss: 0.0057\n",
      "Epoch 4/50\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 2.5562e-04 - val_loss: 0.0052\n",
      "Epoch 5/50\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 1.9094e-04 - val_loss: 0.0107\n",
      "Epoch 6/50\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 3.0628e-04 - val_loss: 0.0078\n",
      "Epoch 7/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 2.8195e-04 - val_loss: 0.0098\n",
      "Epoch 8/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.9320e-04 - val_loss: 0.0058\n",
      "Epoch 9/50\n",
      "65/65 [==============================] - 3s 41ms/step - loss: 2.0019e-04 - val_loss: 0.0053\n",
      "Epoch 10/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 2.0925e-04 - val_loss: 0.0057\n",
      "Epoch 11/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.8714e-04 - val_loss: 0.0074\n",
      "Epoch 12/50\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 1.8284e-04 - val_loss: 0.0054\n",
      "Epoch 13/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.7545e-04 - val_loss: 0.0072\n",
      "Epoch 14/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.7300e-04 - val_loss: 0.0069\n",
      "Epoch 15/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 2.0395e-04 - val_loss: 0.0051\n",
      "Epoch 16/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.3241e-04 - val_loss: 0.0068\n",
      "Epoch 17/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.8994e-04 - val_loss: 0.0066\n",
      "Epoch 18/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.5617e-04 - val_loss: 0.0049\n",
      "Epoch 19/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.5419e-04 - val_loss: 0.0063\n",
      "Epoch 20/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.3975e-04 - val_loss: 0.0056\n",
      "Epoch 21/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.6063e-04 - val_loss: 0.0050\n",
      "Epoch 22/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.0825e-04 - val_loss: 0.0049\n",
      "Epoch 23/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.2863e-04 - val_loss: 0.0074\n",
      "Epoch 24/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.2867e-04 - val_loss: 0.0108\n",
      "Epoch 25/50\n",
      "65/65 [==============================] - 3s 41ms/step - loss: 1.0607e-04 - val_loss: 0.0051\n",
      "Epoch 26/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.3607e-04 - val_loss: 0.0061\n",
      "Epoch 27/50\n",
      "65/65 [==============================] - 3s 41ms/step - loss: 1.2360e-04 - val_loss: 0.0041\n",
      "Epoch 28/50\n",
      "65/65 [==============================] - 3s 41ms/step - loss: 1.0004e-04 - val_loss: 0.0052\n",
      "Epoch 29/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.1233e-04 - val_loss: 0.0095\n",
      "Epoch 30/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.2554e-04 - val_loss: 0.0045\n",
      "Epoch 31/50\n",
      "65/65 [==============================] - 3s 46ms/step - loss: 1.0942e-04 - val_loss: 0.0036\n",
      "Epoch 32/50\n",
      "65/65 [==============================] - 3s 41ms/step - loss: 1.0242e-04 - val_loss: 0.0039\n",
      "Epoch 33/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.3928e-04 - val_loss: 0.0032\n",
      "Epoch 34/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.0833e-04 - val_loss: 0.0053\n",
      "Epoch 35/50\n",
      "65/65 [==============================] - 3s 41ms/step - loss: 1.5727e-04 - val_loss: 0.0028\n",
      "Epoch 36/50\n",
      "65/65 [==============================] - 3s 40ms/step - loss: 1.1041e-04 - val_loss: 0.0036\n",
      "Epoch 37/50\n",
      "65/65 [==============================] - ETA: 0s - loss: 1.5214e-04"
     ]
    }
   ],
   "source": [
    "# Clear session before training model 2 \n",
    "clear_session()\n",
    "\n",
    "model_2 = model_2(x_train, 0.1)\n",
    "history_2 = model_2.fit(x_train, y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3544654-1ad8-4cde-8657-c8d0a89093b6",
   "metadata": {},
   "source": [
    "### 6. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f21a45-5057-405b-8a6a-c70cf0a4de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test, scaler_pred):\n",
    "\n",
    "    # Predict the Ether price\n",
    "    y_pred_scaled = model.predict(x_test)\n",
    "\n",
    "    # Unscale the predicted values\n",
    "    y_pred = scaler_pred.inverse_transform(y_pred_scaled)\n",
    "    y_test_unscaled = scaler_pred.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "    # Evaluate the model\n",
    "    regression_metrics(y_test_unscaled, y_pred)\n",
    "    \n",
    "    return y_test_unscaled, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89306bd2-203d-492b-a050-173f47f49ab2",
   "metadata": {},
   "source": [
    "##### Model 1 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd703a-1055-4563-9ac9-6ffe36800f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model 1:\n",
    "y_test_unscaled, y_pred = evaluate_model(model_1, x_test, y_test, scaler_pred)\n",
    "\n",
    "# Plot training and testing loss values of model 1\n",
    "history_accuracy_loss(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f014da-bb17-4798-8caa-633dd1ec56b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model 1\n",
    "model_1.save('models/LSTM_model_1.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d07e7a-ecc9-486d-8a76-5c764eb90314",
   "metadata": {},
   "source": [
    "##### Model 2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825f38de-d41b-43bf-b079-edc0e128fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model 2:\n",
    "y_test_unscaled_2, y_pred_2 = evaluate_model(model_2, x_test, y_test, scaler_pred)\n",
    "\n",
    "# Plot training and testing loss values of model 2\n",
    "history_accuracy_loss(history_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce070f46-0d48-4e7d-96b5-2665e1cb591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model 2\n",
    "model_2.save('models/LSTM_model_2.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49db085c-e597-4408-9d9b-ea91a1be2209",
   "metadata": {},
   "source": [
    "### 7. Compare the Predicted and Actual Ethereum Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954c635e-49cc-4e20-b0ed-db00b4711d5c",
   "metadata": {},
   "source": [
    "##### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b68c9a2-6c4e-42b2-8dc6-0d8bb0e64931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_actual_predicted(pd.DataFrame(y_test_unscaled), pd.DataFrame(y_pred), 'Actual and Predicted Ethereum Price by LSTM Model 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad1043-f77a-41b7-80b5-7bff12aaefa1",
   "metadata": {},
   "source": [
    "##### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d1daa-568a-4c00-a7ca-e14831068a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_actual_predicted(pd.DataFrame(y_test_unscaled_2), pd.DataFrame(y_pred_2), 'Actual and Predicted Ethereum Price by LSTM Model 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f2500-b8f7-42b1-957c-04d0586036ec",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "As we can see in the evaluation session, Model 1 performs better than Model 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fccd0d-1660-41b5-8c14-273f7d77dcb1",
   "metadata": {},
   "source": [
    "### 8. Predict the next day's price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d6a32-79d2-47cb-833a-f48a9373a6f0",
   "metadata": {},
   "source": [
    "We trained the model with data to 19-Nov, so we will predict the Ether price on 20-Nov based on the 7 previous days (from 13-Nov to 19-Nov). This is for testing purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d6349-0f8d-4ff0-ae07-4827cc8f78e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_day_price(file_name, from_date, to_date, today):\n",
    "   \n",
    "    # Get today price on 20-Nov for checking\n",
    "    df_lasted = pd.read_csv(file_name)\n",
    "    price_today = round(df_lasted[df_lasted['date']=='2021-11-20']['PriceUSD'], 2)\n",
    "\n",
    "    # Get data on last 7 days\n",
    "    from_date = '2021-11-13'\n",
    "    to_date = '2021-11-19'\n",
    "\n",
    "    df_last_7_days = df[(df['date']<=to_date) & (df['date']>=from_date)]\n",
    "\n",
    "    imp_features = ['PriceUSD', 'AdrActCnt', 'AdrBal1in100MCnt',\n",
    "       'AdrBal1in10BCnt', 'AdrBal1in10MCnt', 'AdrBal1in1BCnt',\n",
    "       'AdrBal1in1MCnt', 'CapMrktCurUSD', 'CapRealUSD', 'DiffLast',\n",
    "       'DiffMean', 'FeeMedUSD', 'FeeTotUSD', 'FlowInExUSD',\n",
    "       'FlowOutExUSD', 'GasUsedTx', 'GasUsedTxMean', 'HashRate',\n",
    "       'RevHashNtv', 'RevHashRateNtv', 'RevHashRateUSD',\n",
    "       'SplyAdrBalUSD1M', 'TxCnt', 'TxTfrValMedUSD']\n",
    "\n",
    "    df_last_7_days = df_last_7_days[imp_features]\n",
    "    last_7_days_scaled = scaler.transform(df_last_7_days)\n",
    "\n",
    "    # Create an empty list and append past 7 days\n",
    "    X_test_new = []\n",
    "    X_test_new.append(last_7_days_scaled)\n",
    "\n",
    "    # Predicted price for the next day\n",
    "    pred_price_scaled = model_1.predict(np.array(X_test_new))\n",
    "    pred_price_unscaled = scaler_pred.inverse_transform(pred_price_scaled.reshape(-1, 1))\n",
    "    predicted_price = np.round(pred_price_unscaled.ravel()[0], 2)\n",
    "\n",
    "    # Calculate the difference\n",
    "    change_percent = round(abs(price_today - predicted_price),2)\n",
    "    \n",
    "    return price_today, predicted_price, change_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b499abd8-2423-4c62-b5aa-f4b723f9b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get today's price and compare with the predicted value \n",
    "price_today, predicted_price, change_percent = predict_next_day_price('data/eth_test.csv','2021-11-13', '2021-11-19', '2021-11-20')\n",
    "print('The actual Ether price:', price_today.values)\n",
    "print('The predicted Ether price:', predicted_price)\n",
    "print('The difference is:', change_percent.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8574d51b-4d53-4ed8-8f63-47d5fae7013c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
